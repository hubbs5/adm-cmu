{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Attractor networks provide some level of neural plausibility beyond the standard drift-diffusion model\n",
    "for binary decision making ([Wang 2008](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2710297/)). These nonlinear models represent competing populations\n",
    "of neurons which are working to come to a decision and are easily extendable to $n$ decision paradigms.\n",
    "One of the limitations of these models is their lack of capability to learn from experience. Learning,\n",
    "however, can be addressed through techniques developed in reinforcement learning ([Sutton and Barto\n",
    "2018](https://drive.google.com/file/d/1xeUDVGWGUUv1-ccUMAZHJLej2C7aAFWY/view)). \n",
    "\n",
    "Previous efforts to integrate learning and decision making include [Pederson et al. 2016](https://www.ncbi.nlm.nih.gov/pubmed/27966103) who focused on integrating learning with the drift diffusion model and [Dunovan and Verstynen 2016](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwitu57LovPeAhUr1lkKHW9cAsgQFjAAegQIBxAB&url=https%3A%2F%2Fwww.frontiersin.org%2Farticles%2F10.3389%2Ffnins.2016.00106&usg=AOvVaw1OVlm6Z0LBWt6I1UweF_X9) who introduced the **Believer-Skeptic** model. \n",
    "\n",
    "For this project, I propose an algorithm to combine Q learning with attractor networks to\n",
    "simulate the dynamics of decision making in a learning environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym \n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, env, n_hidden_layers=1, \n",
    "        n_hidden_nodes=4, learning_rate=0.001, bias=False, \n",
    "        activation_function='relu', dqn_algo='vanilla', \n",
    "        device='cpu', *args, **kwargs):\n",
    "        super(QNetwork, self).__init__()\n",
    "        \n",
    "        self.env = env\n",
    "        algo_list = ['vanilla', 'double', 'dueling']\n",
    "        self.dqn_algo = dqn_algo.lower()\n",
    "        assert self.dqn_algo in algo_list, \\\n",
    "            \"dqn_algo {} not recognized, provide one of: {}.\".format(dqn_algo, algo_list)\n",
    "            \n",
    "        self.n_inputs = self.env.observation_space.shape[0]        \n",
    "        self.n_outputs = self.env.action_space.n \n",
    "        # Allow custom layer definition\n",
    "        if len(args) > 0:\n",
    "            self.n_hidden_layers = len(args)\n",
    "        else:\n",
    "            self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_hidden_nodes = n_hidden_nodes\n",
    "        self.bias = bias\n",
    "        self.actions = np.arange(self.n_outputs)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_function = activation_function.lower()\n",
    "        self.device = device\n",
    "\n",
    "        # Build network\n",
    "        layer_list = getLayersAndNodes(self, args)\n",
    "        self.layers = buildNetwork(self, layer_list)\n",
    "        self.net = nn.Sequential(self.layers)\n",
    "        self.net.apply(xavierInit)\n",
    "\n",
    "        if dqn_algo == 'dueling':\n",
    "            dueling_list = getLayersAndNodes(self, args)\n",
    "            dueling_list[-1] = 1\n",
    "            self.dueling_layers = buildNetwork(self, dueling_list)\n",
    "            self.dueling_net = nn.Sequential(self.dueling_layers)\n",
    "            self.dueling_net.apply(xavierInit)\n",
    "\n",
    "        if self.device == 'cuda':\n",
    "            self.net.cuda()\n",
    "            if dqn_algo == 'dueling':\n",
    "                self.dueling_net.cuda()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), \n",
    "            lr=self.learning_rate)\n",
    "     \n",
    "    def getQValues(self, state):\n",
    "        state = flattenDict(state)\n",
    "        try:\n",
    "            state_t = torch.FloatTensor(state).to(device=self.device)\n",
    "        except TypeError:\n",
    "            print(len(state))\n",
    "            print(state)\n",
    "        if self.dqn_algo == 'vanilla':\n",
    "            return self.net(state_t)\n",
    "        elif self.dqn_algo == 'double':\n",
    "            return self.net(state_t)\n",
    "        elif self.dqn_algo == 'dueling':\n",
    "            A = self.net(state_t)\n",
    "            V = self.dueling_net(state_t)\n",
    "            return V + A - A.mean()\n",
    "\n",
    "    def getAction(self, state):\n",
    "        qval, action = torch.max(self.getQValues(state), dim=-1)\n",
    "        return qval.detach(), action.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_parameters = pd.read_csv('project/data/CartPole-v0/dqn/20181128_1928/parameters.txt')\n",
    "parameters = pd.DataFrame(_parameters['value'].values.reshape(1, -1), \n",
    "                          columns=_parameters['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getLayersAndNodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-eebf0b724c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                \u001b[0mactivation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actFunc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                dqn_algo=parameters['dqnAlgo'][0])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-d93baa31bd2b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, n_hidden_layers, n_hidden_nodes, learning_rate, bias, activation_function, dqn_algo, device, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Build network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mlayer_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLayersAndNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getLayersAndNodes' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make(parameters['env'][0])\n",
    "net = QNetwork(env,\n",
    "               hl=int(parameters['hl'][0]),\n",
    "               hn=int(parameters['hn'][0]),\n",
    "               learning_rate=float(parameters['lr'][0]),\n",
    "               bias=bool(parameters['bias'][0]), \n",
    "               activation_function=parameters['actFunc'][0],\n",
    "               dqn_algo=parameters['dqnAlgo'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parameters['hl'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
